{
  "title": "Aggregation & Grouping",
  "description": "A narrative course on aggregation and GROUP BY patterns with DuckDB-friendly examples. Each section explains why the technique matters, asks a concrete question (\"Now let's say we need to X, how do we do it?\"), provides one or more self-contained examples, alternative approaches, and common pitfalls.",
  "sections": [
    {
      "title": "0. Introduction: Aggregation & Grouping",
      "description": "What do aggregations solve and when do we use GROUP BY? A quick, gentle intro with mental models and common functions.",
      "examples": [],
      "narrative": "Aggregation turns many rows into a few numbers that answer business questions: how many orders, how much revenue, what’s the average price. GROUP BY answers ‘per X’ questions: per customer, per product, per month. You’ll primarily use COUNT, SUM, AVG, MIN, and MAX, often combined with date bucketing and CASE expressions to segment data.",
      "nerd_notes": "Key mental model: WHERE filters rows before aggregation; HAVING filters groups after aggregation. COUNT(column) counts non-NULLs while COUNT(*) counts rows. Prefer DECIMAL/NUMERIC for currency. For analytical features like running totals or percent-of-total alongside row detail, use window functions instead of GROUP BY."
    },
    {
      "title": "1. Setup: small sales dataset",
      "description": "Create a small, idempotent sales table used by the lesson. This ensures anyone can re-run the examples from a known starting point.",
      "examples": [
        {
          "name": "create_sales",
          "sql": "DROP TABLE IF EXISTS sales;\nCREATE TABLE sales(\n  sale_id INTEGER,\n  sale_date DATE,\n  customer_id INTEGER,\n  product TEXT,\n  quantity INTEGER,\n  unit_price DOUBLE\n);\n\nINSERT INTO sales VALUES\n(1, '2024-01-01', 101, 'Widget', 2, 10.0),\n(2, '2024-01-02', 102, 'Gadget', 1, 25.0),\n(3, '2024-01-02', 101, 'Widget', 1, 10.0),\n(4, '2024-01-03', 103, 'Doodad', 5, 3.5),\n(5, '2024-01-04', 102, 'Widget', 3, 10.0);",
          "description": "Now let's say we need a small transactional sales dataset to experiment with aggregation — how do we create repeatable demo data?",
          "nerd_notes": "Idempotent setup uses DROP + CREATE + INSERT. In production use DECIMAL for currency, NOT NULL where appropriate, and consider partitioning or ordering for large datasets.",
          "compat_examples": {
            "postgres": "-- PostgreSQL: use SERIAL or IDENTITY for auto-increment\n-- CREATE TABLE sales (sale_id SERIAL PRIMARY KEY, sale_date DATE, customer_id INT, product TEXT, quantity INT, unit_price NUMERIC(10,2));",
            "mysql": "-- MySQL: use AUTO_INCREMENT and appropriate DATATYPE\n-- CREATE TABLE sales (sale_id INT AUTO_INCREMENT PRIMARY KEY, sale_date DATE, customer_id INT, product VARCHAR(255), quantity INT, unit_price DECIMAL(10,2));",
            "oracle": "-- Oracle: older versions use SEQUENCE + trigger; newer versions support IDENTITY (12c+)\n-- CREATE TABLE sales (sale_id NUMBER GENERATED BY DEFAULT AS IDENTITY, sale_date DATE, customer_id NUMBER, product VARCHAR2(4000), quantity NUMBER, unit_price NUMBER(10,2));\n-- -- Or: create sequence sales_seq; then use sales_seq.NEXTVAL in INSERTs."
          }
        }
      ],
      "narrative": "We begin by creating a compact sales dataset so every example runs from a known state. This mirrors how you'd seed test data in a notebook or workshop: simple, repeatable, and focused on the columns we'll analyze (date, customer, product, quantity, price).",
      "nerd_notes": "This setup is intentionally small and denormalized to make examples easy to follow; in real analytics pipelines you may have normalized tables or wide columnar layouts optimized for DuckDB's vectorized engine."
    },
    {
      "title": "1.5 Cheat Sheet: Quick Aggregation Patterns",
      "description": "Copy/paste fast answers using the sales table created above.",
      "examples": [
        {
          "name": "cs_total_revenue",
          "description": "Total revenue across all sales.",
          "sql": "SELECT SUM(quantity * unit_price) AS total_revenue FROM sales;",
          "nerd_notes": "DECIMAL/NUMERIC is safer for money; DOUBLE is fine for demos."
        },
        {
          "name": "cs_revenue_by_product",
          "description": "Revenue by product, highest first.",
          "sql": "SELECT product, SUM(quantity * unit_price) AS revenue FROM sales GROUP BY product ORDER BY revenue DESC, product;",
          "nerd_notes": "Always add a deterministic tiebreaker in ORDER BY (e.g., product)."
        },
        {
          "name": "cs_unique_customers",
          "description": "How many distinct customers?",
          "sql": "SELECT COUNT(DISTINCT customer_id) AS unique_customers FROM sales;",
          "nerd_notes": "COUNT(DISTINCT ...) can be expensive on large data; consider pre-aggregation."
        },
        {
          "name": "cs_monthly_revenue",
          "description": "Monthly revenue buckets.",
          "sql": "SELECT STRFTIME(sale_date, '%Y-%m') AS month, SUM(quantity * unit_price) AS revenue FROM sales GROUP BY month ORDER BY month;",
          "nerd_notes": "Prefer DATE_TRUNC('month', sale_date) if you need date arithmetic on buckets."
        },
        {
          "name": "cs_top2_products_by_revenue",
          "description": "Top 2 products by revenue using a window.",
          "sql": "WITH prod AS (SELECT product, SUM(quantity * unit_price) AS revenue FROM sales GROUP BY product) SELECT product, revenue FROM ( SELECT product, revenue, ROW_NUMBER() OVER (ORDER BY revenue DESC, product) AS rn FROM prod ) WHERE rn <= 2 ORDER BY revenue DESC, product;",
          "nerd_notes": "Compute aggregates first, then rank. Avoid using aggregates directly inside OVER() expressions."
        },
        {
          "name": "cs_percent_of_total",
          "description": "Percent of total revenue per product.",
          "sql": "SELECT product, SUM(quantity * unit_price) AS revenue, ROUND(SUM(quantity * unit_price) * 100.0 / SUM(SUM(quantity * unit_price)) OVER (), 2) AS pct_total FROM sales GROUP BY product ORDER BY revenue DESC, product;",
          "nerd_notes": "SUM(SUM(...)) OVER () is a common pattern for percent-of-total."
        },
        {
          "name": "cs_having_threshold",
          "description": "Customers with revenue > 20.",
          "sql": "SELECT customer_id, SUM(quantity * unit_price) AS customer_revenue FROM sales GROUP BY customer_id HAVING SUM(quantity * unit_price) > 20 ORDER BY customer_revenue DESC, customer_id;",
          "nerd_notes": "HAVING filters after aggregation; WHERE filters before."
        }
      ],
      "narrative": "A compact reference of the most common aggregation queries: totals, per-group sums, distinct counts, date buckets, top-N, and percent-of-total.",
      "nerd_notes": "Favor descriptive aliases and deterministic ORDER BY clauses."
    },
    {
      "title": "1.6 Pitfalls, Tips, and Q&A",
      "description": "Common mistakes and frequently asked questions with concise answers.",
      "examples": [
        {
          "name": "pitfall_count_vs_count_star",
          "description": "Q: Why does COUNT(column) differ from COUNT(*)?",
          "sql": "",
          "nerd_notes": "COUNT(column) ignores NULL rows in that column; COUNT(*) counts all rows. Use COALESCE if you want NULLs treated as zeros before summing."
        },
        {
          "name": "pitfall_only_full_group_by",
          "description": "Q: Why do I get errors when selecting non-aggregated columns without grouping them?",
          "sql": "",
          "nerd_notes": "SQL requires either aggregating or grouping every selected column. Engines like MySQL with ONLY_FULL_GROUP_BY enforce this strictly; comply by grouping the exact expression or using a subquery."
        },
        {
          "name": "tip_decimal_for_currency",
          "description": "Tip: Use DECIMAL/NUMERIC for currency.",
          "sql": "",
          "nerd_notes": "Floating-point DOUBLE can introduce rounding artifacts; use DECIMAL for money and round only at presentation time."
        },
        {
          "name": "tricky_rollup_nulls",
          "description": "Q: Why do ROLLUP rows show NULLs?",
          "sql": "",
          "nerd_notes": "NULLs indicate higher aggregation levels (subtotals/totals). Render with COALESCE or GROUPING() for readability."
        },
        {
          "name": "fundamental_where_vs_having",
          "description": "Q: WHEN do I use WHERE vs HAVING?",
          "sql": "",
          "nerd_notes": "WHERE filters rows before grouping; HAVING filters groups after aggregation. If your predicate refers to an aggregate, use HAVING."
        },
        {
          "name": "question_grouping_sets_value",
          "description": "Q: When should I use ROLLUP/GROUPING SETS instead of UNION ALL?",
          "sql": "",
          "nerd_notes": "Use ROLLUP/GROUPING SETS for concise multi-level subtotals when supported. Use UNION ALL for portability or when you want explicit control over each level."
        }
      ],
      "narrative": "A quick grab bag of ‘gotchas’ and frequently asked questions so you avoid common errors and write portable, predictable queries.",
      "nerd_notes": "Add deterministic ORDER BYs, prefer explicit expressions in GROUP BY, and keep large aggregations memory-aware."
    },
    {
      "title": "2. Basic aggregates",
  "description": "COUNT, SUM, AVG, MIN, MAX over entire table — start with the basic questions: how many rows, what is the total revenue, and what is the average price?",
      "examples": [
        {
          "name": "basic_aggregates",
          "sql": "SELECT\n  COUNT(*) AS total_rows,\n  SUM(quantity * unit_price) AS total_revenue,\n  AVG(unit_price) AS avg_unit_price,\n  MIN(unit_price) AS min_price,\n  MAX(unit_price) AS max_price\nFROM sales;",
          "description": "Now let's say we need to answer: how many sales are in the table, what's the total revenue, and what's the average unit price?",
          "nerd_notes": "Alternatives: you can compute conditional aggregates with FILTER or CASE expressions if you need to restrict what contributes to an aggregate. Pitfall: AVG and SUM ignore NULLs; COUNT(column) counts non-NULLs while COUNT(*) counts all rows. For high-volume data consider storing pre-aggregated summaries or using proper column types.",
          "compat_examples": {
            "postgres": "-- Portable SQL: basic aggregates are standard ANSI SQL and work in Postgres as-is.",
            "mysql": "-- Portable SQL: basic aggregates are standard ANSI SQL and work in MySQL as-is.",
            "oracle": "-- Portable SQL: basic aggregates are standard ANSI SQL and work in Oracle as-is."
          }
        }
      ],
  "narrative": "This section walks through the simplest aggregate functions (COUNT, SUM, AVG, MIN, MAX), explains what each one answers, and shows quick examples that map questions to SQL. Think of this as the 'calculator' you use when you want a single-number summary of a table.",
  "nerd_notes": "AVG and SUM ignore NULLs; COUNT(column) counts non-NULLs while COUNT(*) counts rows. For money use DECIMAL and consider rounding in presentation layers."
    },
    {
      "title": "3. GROUP BY basics",
  "description": "Group by product and compute aggregates per group — question-first: how much did each product contribute to revenue?",
      "examples": [
        {
          "name": "group_by_product",
          "sql": "SELECT product,\n  SUM(quantity) AS total_quantity,\n  SUM(quantity * unit_price) AS revenue,\n  AVG(unit_price) AS avg_price\nFROM sales\nGROUP BY product\nORDER BY revenue DESC;",
          "description": "Now let's say we need to compare products by total quantity sold and revenue — how do we write that query?",
          "nerd_notes": "Alternative: if you need top-N per product consider window functions (ROW_NUMBER() OVER (PARTITION BY ... ORDER BY ...)). Watch out for grouping by expressions — include the exact expression in GROUP BY.",
          "compat_examples": {
            "postgres": "-- Portable SQL: GROUP BY usage is standard and runs in Postgres without changes.",
            "mysql": "-- Portable SQL: GROUP BY works in MySQL; beware of ONLY_FULL_GROUP_BY mode if selecting non-aggregated columns.",
            "oracle": "-- Portable SQL: GROUP BY works in Oracle; use TO_CHAR/DATE_TRUNC equivalents when grouping by dates."
          }
        }
      ],
  "narrative": "Grouping lets you answer 'per X' questions: per product, per customer, per month. This narrative explains why grouping is essential for segmented summaries and the typical gotchas when grouping by expressions or multiple columns.",
  "nerd_notes": "When grouping by expressions keep the exact expression consistent between SELECT and GROUP BY, or use a subquery/CTE to avoid duplication."
    },
    {
      "title": "4. HAVING to filter groups",
  "description": "Filter groups after aggregation — question: how do we select only customers whose aggregated revenue exceeds a threshold?",
      "examples": [
        {
          "name": "having_filter",
          "sql": "SELECT customer_id, SUM(quantity * unit_price) AS customer_revenue\nFROM sales\nGROUP BY customer_id\nHAVING SUM(quantity * unit_price) > 20;",
          "description": "Now let's say we want only customers whose total spend is more than 20 — how do we express that?",
          "nerd_notes": "HAVING runs after aggregation. Don't confuse WHERE (filters rows before aggregation) with HAVING (filters groups). For complex predicates you can compute the aggregate in a subquery then filter in an outer WHERE if the engine's optimizer benefits from it.",
          "compat_examples": {
            "postgres": "-- Portable SQL: HAVING is supported by Postgres as-is.",
            "mysql": "-- Portable SQL: HAVING is supported by MySQL as-is.",
            "oracle": "-- Portable SQL: HAVING is supported by Oracle as-is."
          }
        }
      ],
  "narrative": "HAVING answers the question 'which groups meet this aggregated condition?'. Use WHERE to limit rows before grouping and HAVING to filter after aggregation. This section explains the difference with examples and when to prefer a derived table for clarity or performance.",
  "nerd_notes": "Prefer derived tables when you refer to computed aggregates multiple times or when the aggregator is expensive; some engines optimize HAVING poorly."
    },
    {
      "title": "5. GROUPING SETS / ROLLUP (DuckDB supports ROLLUP)",
  "description": "Produce subtotals and totals using ROLLUP — question: how can we get product/month subtotals and a grand total in a single query?",
      "examples": [
        {
          "name": "rollup_example",
          "sql": "SELECT product, STRFTIME(sale_date, '%Y-%m') AS month,\n  SUM(quantity * unit_price) AS revenue\nFROM sales\nGROUP BY ROLLUP(product, month)\nORDER BY product NULLS LAST, month NULLS LAST;",
          "description": "Now let's say we want subtotals by product and month and also a grand total — can we get them all together?",
          "nerd_notes": "ROLLUP produces NULLs for higher aggregation levels; use COALESCE or GROUPING() to render readable labels. Alternative: UNION ALL multiple grouped queries (works on any SQL dialect), but ROLLUP is more concise and often faster. Pitfall: be explicit about ordering so NULL rows (totals) appear where you expect.",
          "compat_examples": {
            "postgres": "-- PostgreSQL: Postgres supports ROLLUP and GROUPING() functions; use TO_CHAR for date formatting if desired.",
            "mysql": "-- MySQL: older MySQL versions may not support ROLLUP with the same semantics; emulate with UNION ALL if needed.",
            "oracle": "-- Oracle: supports ROLLUP and GROUPING(); use TO_CHAR(date,'YYYY-MM') for month buckets."
          }
        }
      ],
  "narrative": "ROLLUP produces hierarchical aggregates (detail, subtotals, grand total) in one result set — a very practical pattern for reports. We'll show how NULLs represent higher aggregation levels and how to label them for human-readable output.",
  "nerd_notes": "DuckDB supports ROLLUP; if your engine doesn't, emulate the behavior with UNION ALL of grouped queries. Use COALESCE or GROUPING() to render readable labels in reports."
    },
    {
      "title": "6. Windowed aggregation vs GROUP BY",
  "description": "Use window functions to keep row-level detail while seeing group aggregates — question: how do I show a row's details and the group's total revenue side-by-side?",
      "examples": [
        {
          "name": "window_vs_group",
          "sql": "SELECT *,\n  SUM(quantity * unit_price) OVER (PARTITION BY customer_id) AS revenue_by_customer\nFROM sales\nORDER BY customer_id, sale_date;",
          "description": "Now let's say we want to show each sale but also the total revenue for the same customer — how do we attach the group total without collapsing rows?",
          "nerd_notes": "Window functions like SUM(...) OVER (PARTITION BY ...) compute aggregates per row while preserving rows. Alternative approaches include joining against a grouped subquery; window functions are often simpler and can be more efficient. Pitfall: ordering in the OVER clause matters for running totals.",
          "compat_examples": {
            "postgres": "-- PostgreSQL: window functions are supported as-is.",
            "mysql": "-- MySQL: window functions are supported in 8.0+; for older versions emulate using joins.",
            "oracle": "-- Oracle: window functions are supported as-is; syntax may vary for framing clauses."
          }
        }
      ],
  "narrative": "Window functions let you keep row-level detail while computing group-level aggregates (running totals, ranks, per-partition sums). This is critical for time-series reporting and comparisons where you don't want to collapse rows.",
  "nerd_notes": "Window functions may require memory proportional to partition size. For very large partitions consider pre-aggregating or using streaming/windowed approaches."
    },
    
    {
      "title": "Aggregation & Grouping - Complete Guide",
      "narrative": "A worked example showing detail rows, subtotals, and a grand total using ROLLUP; we'll also show how to make the NULLs readable and how to fall back to UNION ALL when ROLLUP isn't available.",
      "nerd_notes": "Use COALESCE or GROUPING() to produce friendly labels for aggregated rows. Emulate ROLLUP with UNION ALL when necessary.",
      "examples": [
        {
          "name": "rollup_report_example",
          "description": "Question: how do we present a report with product/month subtotals and a grand total in one result set?",
          "sql": "DROP TABLE IF EXISTS sales_rollup;\nCREATE TABLE sales_rollup(sale_id INTEGER, sale_date DATE, customer_id INTEGER, product TEXT, quantity INTEGER, unit_price DOUBLE);\nINSERT INTO sales_rollup VALUES (1,'2024-01-01',101,'Widget',2,10.0),(2,'2024-01-02',102,'Gadget',1,25.0),(3,'2024-01-02',101,'Widget',1,10.0),(4,'2024-01-03',103,'Doodad',5,3.5),(5,'2024-01-04',102,'Widget',3,10.0);\n\nSELECT COALESCE(product,'<ALL PRODUCTS>') AS product, COALESCE(STRFTIME(sale_date,'%Y-%m'),'<ALL MONTHS>') AS month, SUM(quantity * unit_price) AS revenue,\n  CASE WHEN product IS NULL AND STRFTIME(sale_date,'%Y-%m') IS NULL THEN 'Grand Total'\n       WHEN product IS NULL THEN 'All Products'\n       WHEN STRFTIME(sale_date,'%Y-%m') IS NULL THEN 'All Months'\n       ELSE 'Detail' END AS level\nFROM sales_rollup\nGROUP BY ROLLUP(product, STRFTIME(sale_date,'%Y-%m'))\nORDER BY product NULLS LAST, month NULLS LAST;",
          "nerd_notes": "STRFTIME and COALESCE are used to make rollup rows readable. DuckDB supports ROLLUP; if you target another engine, either test GROUPING() support or emulate using UNION ALL.",
          "compat_examples": {
            "postgres": "-- PostgreSQL: use TO_CHAR or DATE_TRUNC for month\n-- SELECT COALESCE(product,'<ALL>') AS product, COALESCE(TO_CHAR(sale_date,'YYYY-MM'),'<ALL MONTHS>') AS month, SUM(quantity * unit_price) FROM sales_rollup GROUP BY ROLLUP(product, TO_CHAR(sale_date,'YYYY-MM'));",
            "mysql": "-- MySQL: use DATE_FORMAT for month and ROLLUP available as extension in some engines; emulate with UNION ALL\n-- SELECT COALESCE(product,'<ALL>') AS product, COALESCE(DATE_FORMAT(sale_date,'%Y-%m'),'<ALL MONTHS>') AS month, SUM(quantity * unit_price) FROM sales_rollup GROUP BY product, month WITH ROLLUP;",
            "oracle": "-- Oracle: use TO_CHAR for month and GROUPING() for labels\n-- SELECT NVL(product,'<ALL>') AS product, NVL(TO_CHAR(sale_date,'YYYY-MM'),'<ALL MONTHS>') AS month, SUM(quantity * unit_price) FROM sales_rollup GROUP BY ROLLUP(product, TO_CHAR(sale_date,'YYYY-MM'));"
          }
        }
      ]
    },
    {
      "title": "Basic Aggregation Functions",
      "narrative": "Demonstrates COUNT(DISTINCT) and FILTER so you can compute conditional aggregates without repeating expressions. Each example starts with a practical question and then shows the SQL answer.",
      "nerd_notes": "FILTER keeps conditional logic adjacent to the aggregate. DISTINCT can be expensive on large datasets; consider pre-aggregation or approximate methods for very large cardinalities.",
      "examples": [
        {
          "name": "count_distinct_and_filter",
          "description": "Now let's say we want the number of unique customers and the quantity sold when unit_price > 10 — how can we compute both in one query?",
          "sql": "SELECT\n  COUNT(DISTINCT customer_id) AS unique_customers,\n  SUM(quantity) FILTER (WHERE unit_price > 10) AS high_price_quantity,\n  SUM(quantity) AS total_quantity\nFROM sales;",
          "nerd_notes": "FILTER is syntactic sugar for conditional aggregates and often easier to read than CASE expressions.",
          "compat_examples": {
            "postgres": "-- Postgres: FILTER clause is supported as-is.",
            "mysql": "-- MySQL: FILTER is not supported; use SUM(CASE WHEN ... THEN value ELSE 0 END) instead.",
            "oracle": "-- Oracle: use SUM(CASE WHEN ... THEN value ELSE 0 END) to emulate FILTER."
          }
        },
        {
          "name": "aggregates_and_nulls",
          "description": "Question: how do aggregates treat NULLs? We'll use a small inline sample to show behavior of AVG, SUM, and COUNT.",
          "sql": "WITH sample(q) AS (VALUES (1),(NULL),(3)) SELECT AVG(q) AS avg_q, SUM(q) AS sum_q, COUNT(q) AS count_non_null FROM sample;",
          "nerd_notes": "AVG and SUM ignore NULLs; COUNT(column) counts non-NULLs, COUNT(*) counts all rows. Use COALESCE to treat NULLs as zeros when appropriate.",
          "compat_examples": {
            "postgres": "-- Portable SQL: NULL behavior for aggregates is ANSI standard and consistent in Postgres.",
            "mysql": "-- Portable SQL: NULL behavior for aggregates is ANSI standard and consistent in MySQL.",
            "oracle": "-- Portable SQL: NULL behavior for aggregates is ANSI standard and consistent in Oracle."
          }
        }
      ]
    },
    {
      "title": "GROUP BY multiple columns",
      "narrative": "Group by multiple columns (for example customer + month) to produce time-series or segmented aggregates. We'll show both string buckets and DATE_TRUNC approaches so you can choose what fits your reporting needs.",
      "nerd_notes": "STRFTIME gives text buckets, DATE_TRUNC('month', ...) yields a DATE for easier date arithmetic. Be explicit about timezones for timestamp bucketing.",
      "examples": [
        {
          "name": "group_by_customer_month",
          "description": "Now let's say we want monthly totals per customer — how do we bucket by month and aggregate?",
          "sql": "SELECT customer_id, STRFTIME(sale_date, '%Y-%m') AS month, SUM(quantity) AS total_qty FROM sales GROUP BY customer_id, month ORDER BY customer_id, month;",
          "nerd_notes": "If you prefer date types, use DATE_TRUNC('month', sale_date) AS month_start and GROUP BY that expression.",
          "compat_examples": {
            "postgres": "-- Postgres: DATE_TRUNC('month', sale_date) returns a timestamp/date suitable for grouping.",
            "mysql": "-- MySQL: use DATE_FORMAT(sale_date, '%Y-%m-01') or LAST_DAY alternatives for month bucketing.",
            "oracle": "-- Oracle: use TRUNC(sale_date, 'MM') for month bucketing."
          }
        }
      ]
    },
    {
      "title": "HAVING to filter groups",
      "narrative": "Use HAVING to filter groups after aggregation — for example, finding customers whose total spend exceeds a threshold. We'll compare HAVING with derived-table patterns so you understand when each is clearer or faster.",
      "nerd_notes": "Some SQL engines let you reference aliases in HAVING; for portability use the full aggregate. Derived tables help when you reuse aggregates.",
      "examples": [
        {
          "name": "having_count_example",
          "description": "Question: which customers have made more than one purchase?",
          "sql": "SELECT customer_id, COUNT(*) AS sale_count FROM sales GROUP BY customer_id HAVING COUNT(*) > 1;",
          "nerd_notes": "A derived-table alternative: SELECT customer_id, sale_count FROM (SELECT customer_id, COUNT(*) AS sale_count FROM sales GROUP BY customer_id) t WHERE sale_count > 1;",
          "compat_examples": {
            "postgres": "-- Portable SQL: HAVING and derived table patterns work in Postgres as-is.",
            "mysql": "-- Portable SQL: HAVING and derived table patterns work in MySQL as-is.",
            "oracle": "-- Portable SQL: HAVING and derived table patterns work in Oracle as-is."
          }
        }
      ]
    },
    {
      "title": "Advanced grouping: combining aggregates with window functions",
      "narrative": "Keep row-level detail while adding group aggregates using window functions: perfect for showing per-row metrics alongside the group's totals or ranks. We'll ask the question first and then show the SQL patterns.",
      "nerd_notes": "Use ROW_NUMBER, RANK, and SUM(...) OVER (PARTITION BY ...) for top-N and per-partition metrics. Watch memory for large partitions.",
      "examples": [
        {
          "name": "agg_plus_window",
          "description": "Now let's say we want each sale row but also the total revenue for the product — how do we attach that value without collapsing rows?",
          "sql": "SELECT sale_id, product, quantity, unit_price, SUM(quantity * unit_price) OVER (PARTITION BY product) AS revenue_per_product FROM sales ORDER BY product, sale_id;",
          "nerd_notes": "Joining to a grouped subquery is an alternative and sometimes more memory-friendly for very large partitions.",
          "compat_examples": {
            "postgres": "-- Postgres: window functions supported as-is.",
            "mysql": "-- MySQL: window functions supported in 8.0+; older versions need joins.",
            "oracle": "-- Oracle: window functions supported; syntax for framing is similar."
          }
        }
      ]
    },
    {
      "title": "Sales data: alternate demo from HTML",
      "narrative": "The HTML lesson includes alternate demo datasets (sales_data and customer_purchases) that show aggregation in more business-like schemas. We include them here as self-contained examples so you can run them directly in DuckDB.",
      "nerd_notes": "These examples mirror the HTML's SQL but are adjusted to be DuckDB-friendly (DATE_TRUNC used for month bucketing where applicable).",
      "examples": [
        {
          "name": "sales_data_setup",
          "description": "Question: how do we create a realistic sales table (products, categories, prices) for aggregation drills?",
          "sql": "DROP TABLE IF EXISTS sales_data;\nCREATE TABLE sales_data (\n  sale_id INTEGER PRIMARY KEY,\n  product_name VARCHAR,\n  category VARCHAR,\n  price DOUBLE,\n  quantity INTEGER,\n  sale_date DATE,\n  region VARCHAR\n);\n\nINSERT INTO sales_data (sale_id, product_name, category, price, quantity, sale_date, region) VALUES\n(1,'Laptop','Electronics',999.99,5,'2024-01-15','North'),\n(2,'Mouse','Electronics',25.99,20,'2024-01-16','South'),\n(3,'Book','Education',15.99,30,'2024-01-15','North'),\n(4,'Tablet','Electronics',499.99,8,'2024-01-17','East'),\n(5,'Notebook','Education',5.99,50,'2024-01-16','West'),\n(6,'Headphones','Electronics',79.99,15,'2024-01-18','North');",
          "nerd_notes": "Use DOUBLE or DECIMAL for prices; primary keys help some tools and make examples deterministic.",
          "compat_examples": {
            "postgres": "-- Postgres: use NUMERIC/DECIMAL for currency and SERIAL/IDENTITY for PK if desired.",
            "mysql": "-- MySQL: use DECIMAL for currency and AUTO_INCREMENT for PK if desired.",
            "oracle": "-- Oracle: use NUMBER types and sequences for PK if not using IDENTITY."
          }
        },
        {
          "name": "sales_data_basic_aggregates",
          "description": "Question: what are the overall sales metrics (total revenue, avg price, total quantity) for this dataset?",
          "sql": "SELECT COUNT(*) AS total_sales, COUNT(DISTINCT product_name) AS unique_products, AVG(price) AS average_price, MIN(price) AS cheapest_price, MAX(price) AS most_expensive, SUM(quantity) AS total_quantity_sold, SUM(price * quantity) AS total_revenue FROM sales_data;",
          "nerd_notes": "These are classic single-number summaries used in dashboards and sanity checks.",
          "compat_examples": {
            "postgres": "-- Portable SQL: aggregates are ANSI SQL and work in Postgres.",
            "mysql": "-- Portable SQL: aggregates are ANSI SQL and work in MySQL.",
            "oracle": "-- Portable SQL: aggregates are ANSI SQL and work in Oracle."
          }
        },
        {
          "name": "sales_data_by_category",
          "description": "Question: how does revenue vary by category?",
          "sql": "SELECT category, COUNT(*) AS sales_count, AVG(price) AS avg_price, SUM(quantity) AS total_quantity, SUM(price * quantity) AS category_revenue, MIN(price) AS min_price, MAX(price) AS max_price FROM sales_data GROUP BY category ORDER BY category_revenue DESC;",
          "nerd_notes": "Ordering by revenue surfaces top-performing categories; use LIMIT for top-N.",
          "compat_examples": {
            "postgres": "-- Portable SQL: GROUP BY/ORDER BY works in Postgres.",
            "mysql": "-- Portable SQL: GROUP BY/ORDER BY works in MySQL.",
            "oracle": "-- Portable SQL: GROUP BY/ORDER BY works in Oracle."
          }
        }
      ]
    },
    {
      "title": "Customer purchases demo",
      "narrative": "A lightweight customer_purchases table shows grouping by country/city and grouping by calculated price tiers — useful to practice GROUP BY with expressions.",
      "examples": [
        {
          "name": "customer_purchases_setup",
          "description": "Question: create a customer_purchases table used for grouping exercises.",
          "sql": "DROP TABLE IF EXISTS customer_purchases;\nCREATE TABLE customer_purchases (\n  customer_id INTEGER,\n  customer_name VARCHAR,\n  city VARCHAR,\n  country VARCHAR,\n  purchase_amount DOUBLE,\n  purchase_date DATE,\n  product_category VARCHAR\n);\n\nINSERT INTO customer_purchases VALUES\n(1,'John Smith','New York','USA',299.99,'2024-01-15','Electronics'),\n(2,'Jane Doe','Los Angeles','USA',149.99,'2024-01-16','Books'),\n(3,'Bob Johnson','Chicago','USA',79.99,'2024-01-17','Clothing'),\n(4,'Alice Brown','New York','USA',399.99,'2024-01-18','Electronics'),\n(5,'Charlie Wilson','London','UK',199.99,'2024-01-19','Books'),\n(6,'Diana Davis','London','UK',89.99,'2024-01-20','Clothing'),\n(7,'Eve Garcia','Paris','France',249.99,'2024-01-21','Electronics'),\n(8,'Frank Miller','New York','USA',59.99,'2024-01-22','Books');",
          "nerd_notes": "This dataset is good for exploring regional aggregates and segmentation.",
          "compat_examples": {
            "postgres": "-- Postgres: use NUMERIC for currency if you need exact decimals.",
            "mysql": "-- MySQL: use DECIMAL for currency for consistent rounding.",
            "oracle": "-- Oracle: use NUMBER for currency columns and sequences/IDENTITY as needed."
          }
        },
        {
          "name": "customer_by_country",
          "description": "Question: how much has each country spent and how many customers does it have?",
          "sql": "SELECT country, COUNT(*) AS customer_count, SUM(purchase_amount) AS total_spent, AVG(purchase_amount) AS avg_purchase, MIN(purchase_amount) AS min_purchase, MAX(purchase_amount) AS max_purchase FROM customer_purchases GROUP BY country ORDER BY total_spent DESC;",
          "nerd_notes": "Use LEFT JOIN against customer tables when you want to include zero-values for missing countries.",
          "compat_examples": {
            "postgres": "-- Portable SQL: GROUP BY aggregates are standard and work in Postgres.",
            "mysql": "-- Portable SQL: GROUP BY aggregates are standard and work in MySQL.",
            "oracle": "-- Portable SQL: GROUP BY aggregates are standard and work in Oracle."
          }
        },
        {
          "name": "customer_price_tiers",
          "description": "Question: how do purchases distribute across price tiers (budget/standard/premium)?",
          "sql": "SELECT CASE WHEN purchase_amount < 100 THEN 'Budget (< $100)' WHEN purchase_amount < 200 THEN 'Standard ($100-$199)' WHEN purchase_amount < 300 THEN 'Premium ($200-$299)' ELSE 'Luxury (>= $300)' END AS price_tier, COUNT(*) AS purchases_in_tier, SUM(purchase_amount) AS tier_total, AVG(purchase_amount) AS tier_average FROM customer_purchases GROUP BY price_tier ORDER BY tier_average DESC;",
          "nerd_notes": "Grouping by CASE expressions is common; to avoid duplication, use a CTE that computes the tier first.",
          "compat_examples": {
            "postgres": "-- Portable SQL: CASE expressions are ANSI and supported in Postgres.",
            "mysql": "-- Portable SQL: CASE expressions are ANSI and supported in MySQL.",
            "oracle": "-- Portable SQL: CASE expressions are ANSI and supported in Oracle."
          }
        }
      ]
    },
    {
      "title": "GROUP BY - complete examples from the HTML",
      "narrative": "The HTML file contains a long set of grouping examples: multiple columns, date grouping, UNION ALL emulations for ROLLUP, and GROUP BY with windowed comparisons. We've consolidated the most useful ones here in DuckDB-friendly form.",
      "examples": [
        {
          "name": "create_orders_setup",
          "description": "Question: create a small `orders` table used for date-part grouping examples.",
          "sql": "DROP TABLE IF EXISTS order_items;\nDROP TABLE IF EXISTS orders;\nCREATE TABLE orders (order_id INTEGER PRIMARY KEY, customer_id INTEGER, total_amount DOUBLE, order_date DATE);\nINSERT INTO orders VALUES (1,1,100.0,'2024-01-15'), (2,2,150.0,'2024-01-16'), (3,1,75.0,'2024-02-01');",
          "nerd_notes": "A tiny orders table to make the date-grouping examples self-contained.",
          "compat_examples": {
            "postgres": "-- Postgres: use SERIAL/IDENTITY for order_id if desired.",
            "mysql": "-- MySQL: use AUTO_INCREMENT for order_id if desired.",
            "oracle": "-- Oracle: use SEQUENCE or IDENTITY for order_id depending on version."
          }
        },
        {
          "name": "create_customers_setup",
          "description": "Question: create a small `customers` table used by ROLLUP/UNION examples.",
          "sql": "DROP TABLE IF EXISTS customers;\nCREATE TABLE customers (customer_id INTEGER PRIMARY KEY, country VARCHAR, city VARCHAR);\nINSERT INTO customers VALUES (1,'USA','New York'), (2,'UK','London'), (3,'France','Paris');",
          "nerd_notes": "Simple customers table so rollup_emulation_union_all runs without external dependencies.",
          "compat_examples": {
            "postgres": "-- Postgres: use SERIAL/IDENTITY for PK if desired.",
            "mysql": "-- MySQL: use AUTO_INCREMENT for PK if desired.",
            "oracle": "-- Oracle: use SEQUENCE or IDENTITY for PK depending on version."
          }
        },
        {
          "name": "group_by_date_parts",
          "description": "Question: how do we aggregate orders by year and month?",
          "sql": "SELECT STRFTIME('%Y', order_date) AS year, STRFTIME('%m', order_date) AS month, COUNT(*) AS order_count, SUM(total_amount) AS monthly_revenue, AVG(total_amount) AS avg_order_value, COUNT(DISTINCT customer_id) AS unique_customers FROM orders GROUP BY STRFTIME('%Y', order_date), STRFTIME('%m', order_date) ORDER BY year DESC, month DESC;",
          "nerd_notes": "Alternatively, DATE_TRUNC('month', order_date) is preferable when you need date arithmetic on the bucket.",
          "compat_examples": {
            "postgres": "-- Postgres: DATE_TRUNC('month', order_date) works and returns a timestamp suitable for grouping.",
            "mysql": "-- MySQL: use DATE_FORMAT(order_date,'%Y-%m') or DATE_FORMAT(order_date,'%Y-%m-01') for grouping by month.",
            "oracle": "-- Oracle: use TRUNC(order_date,'MM') for month grouping."
          }
        },
        {
          "name": "rollup_emulation_union_all",
          "description": "Question: how can we emulate ROLLUP using UNION ALL (portable approach)?",
          "sql": "-- Emulate rollup with UNION ALL for engines without ROLLUP\nSELECT country, city, COUNT(*) AS customer_count FROM customers GROUP BY country, city\nUNION ALL\nSELECT country, 'ALL CITIES' AS city, COUNT(*) AS customer_count FROM customers GROUP BY country\nUNION ALL\nSELECT 'ALL COUNTRIES' AS country, 'ALL CITIES' AS city, COUNT(*) AS customer_count FROM customers;",
          "nerd_notes": "UNION ALL approach is portable and explicit; ROLLUP is more concise when available.",
          "compat_examples": {
            "postgres": "-- Postgres: you can use ROLLUP or the UNION ALL emulation; both are supported.",
            "mysql": "-- MySQL: use UNION ALL emulation for full portability; check ROLLUP support in your MySQL version.",
            "oracle": "-- Oracle: supports ROLLUP; UNION ALL emulation also works."
          }
        }
      ]
    },
    {
      "title": "Advanced analytical aggregations (from HTML)",
      "narrative": "The HTML included a 'sales_performance' dataset and a large analytical query set (running totals, ranks, percentiles). We include a curated, DuckDB-friendly subset that highlights running totals, ranking, and partitioned aggregates.",
      "examples": [
        {
          "name": "sales_performance_setup",
          "description": "Question: create a sales_performance table to explore running totals and rankings.",
          "sql": "DROP TABLE IF EXISTS sales_performance;\nCREATE TABLE sales_performance (sale_id INTEGER PRIMARY KEY, salesperson_id INTEGER, salesperson_name VARCHAR, region VARCHAR, product_category VARCHAR, sale_date DATE, sale_amount DOUBLE, quantity INTEGER, customer_rating INTEGER);\n\nINSERT INTO sales_performance VALUES\n(1,1,'Alice Johnson','North','Electronics','2024-01-15',1250.00,5,5),\n(2,1,'Alice Johnson','North','Electronics','2024-01-20',890.00,3,4),\n(3,2,'Bob Smith','South','Clothing','2024-01-18',650.00,8,4),\n(4,2,'Bob Smith','South','Electronics','2024-01-22',1100.00,4,5),\n(5,3,'Carol Davis','East','Books','2024-01-16',320.00,12,3),\n(6,3,'Carol Davis','East','Electronics','2024-01-25',950.00,3,4),\n(7,4,'David Wilson','West','Clothing','2024-01-19',780.00,10,5),\n(8,4,'David Wilson','West','Books','2024-01-23',450.00,15,4);",
          "nerd_notes": "This table is synthetic but simulates salesperson-level time series for analytics.",
          "compat_examples": {
            "postgres": "-- Postgres: use NUMERIC/DECIMAL for monetary columns if you need precise currency arithmetic.",
            "mysql": "-- MySQL: use DECIMAL for monetary columns to avoid floating point rounding issues.",
            "oracle": "-- Oracle: use NUMBER types for monetary columns and consider sequences for PKs if needed."
          }
        },
        {
          "name": "running_totals_and_ranks",
          "description": "Question: how do we compute running totals by salesperson and rank sales within each region?",
          "sql": "SELECT salesperson_name, region, product_category, sale_date, sale_amount, SUM(sale_amount) OVER (PARTITION BY salesperson_id ORDER BY sale_date) AS running_total_by_person, SUM(sale_amount) OVER (PARTITION BY region ORDER BY sale_date) AS running_total_by_region, ROUND(sale_amount * 100.0 / SUM(sale_amount) OVER (PARTITION BY salesperson_id), 2) AS pct_of_person_total, RANK() OVER (PARTITION BY region ORDER BY sale_amount DESC) AS rank_in_region FROM sales_performance ORDER BY salesperson_name, sale_date;",
          "nerd_notes": "Window functions answer many per-row analytical questions without collapsing rows; use ROWS BETWEEN when you need fixed-window running aggregates.",
          "compat_examples": {
            "postgres": "-- Postgres: window functions and RANK() supported as-is.",
            "mysql": "-- MySQL: window functions supported in 8.0+; older versions require emulation.",
            "oracle": "-- Oracle: window functions supported; syntax for framing clauses follows Oracle conventions."
          }
        }
      ]
    },
    {
      "title": "Statistical aggregations (sensor example from HTML)",
      "narrative": "Sensor readings are a common analytic input. The HTML had a long statistical example — here we keep the most useful aggregations (count, mean, stddev, daily aggregates) and avoid engine-specific percentile hacks.",
      "examples": [
        {
          "name": "sensor_readings_setup",
          "description": "Question: create a sensor_readings table used for statistical aggregation examples.",
          "sql": "DROP TABLE IF EXISTS sensor_readings;\nCREATE TABLE sensor_readings (reading_id INTEGER PRIMARY KEY, sensor_id INTEGER, sensor_type VARCHAR, location VARCHAR, reading_value DOUBLE, reading_unit VARCHAR, reading_date DATE, reading_time TIME, quality_score INTEGER);\n\nINSERT INTO sensor_readings VALUES\n(1,1,'Temperature','Building A - Floor 1',22.5,'Celsius','2024-01-15','08:00:00',95),\n(2,1,'Temperature','Building A - Floor 1',23.1,'Celsius','2024-01-15','09:00:00',92),\n(3,1,'Temperature','Building A - Floor 1',21.8,'Celsius','2024-01-15','10:00:00',98),\n(4,2,'Humidity','Building A - Floor 1',45.2,'Percent','2024-01-15','08:00:00',90),\n(5,2,'Humidity','Building A - Floor 1',47.8,'Percent','2024-01-15','09:00:00',88),\n(6,2,'Humidity','Building A - Floor 1',43.5,'Percent','2024-01-15','10:00:00',95),\n(7,3,'Pressure','Building B - Roof',1013.2,'hPa','2024-01-15','08:00:00',97),\n(8,3,'Pressure','Building B - Roof',1012.8,'hPa','2024-01-15','09:00:00',94),\n(9,3,'Pressure','Building B - Roof',1014.1,'hPa','2024-01-15','10:00:00',96);",
          "nerd_notes": "Small synthetic sensor dataset to illustrate mean/stddev and daily aggregation patterns.",
          "compat_examples": {
            "postgres": "-- Postgres: use DOUBLE PRECISION or NUMERIC for reading_value depending on precision needs.",
            "mysql": "-- MySQL: use DOUBLE or DECIMAL for reading_value depending on precision needs.",
            "oracle": "-- Oracle: use NUMBER for reading_value and appropriate scale/precision."
          }
        },
        {
          "name": "sensor_daily_stats",
          "description": "Question: how do we compute daily summary stats (count, mean, min, max, stddev) per sensor_type?",
          "sql": "SELECT sensor_type, reading_unit, COUNT(*) AS total_readings, ROUND(AVG(reading_value),3) AS mean_value, ROUND(MIN(reading_value),3) AS min_value, ROUND(MAX(reading_value),3) AS max_value, ROUND(STDDEV_POP(reading_value),3) AS std_deviation, ROUND(AVG(quality_score),2) AS avg_quality_score FROM sensor_readings GROUP BY sensor_type, reading_unit ORDER BY sensor_type;",
          "nerd_notes": "DuckDB supports STDDEV_POP and STDDEV_SAMP; choose the one that matches your statistical assumptions.",
          "compat_examples": {
            "postgres": "-- Postgres: STDDEV_POP and STDDEV_SAMP are supported; use native functions.",
            "mysql": "-- MySQL: STDDEV_POP and STDDEV_SAMP may be available depending on version; otherwise use STDDEV() which maps to sample stdev.",
            "oracle": "-- Oracle: use STDDEV/STDDEV_POP functions depending on required estimator."
          }
        }
      ]
    },
    {
      "title": "Retail multi-level grouping (from HTML)",
      "narrative": "A retail_sales example demonstrates multi-level grouping (region, store, category, subcategory), rolling aggregates, and cross-dimensional comparisons. We include a curated subset suitable for DuckDB validation and learning.",
      "examples": [
        {
          "name": "retail_sales_setup",
          "description": "Question: create a retail_sales table to practice multi-level grouping and time-based aggregations.",
          "sql": "DROP TABLE IF EXISTS retail_sales;\nCREATE TABLE retail_sales (sale_id INTEGER PRIMARY KEY, store_id INTEGER, store_name VARCHAR, region VARCHAR, product_id INTEGER, product_name VARCHAR, category VARCHAR, subcategory VARCHAR, sale_date DATE, quantity INTEGER, unit_price DOUBLE, discount_percent DOUBLE, customer_type VARCHAR, payment_method VARCHAR);\n\nINSERT INTO retail_sales VALUES\n(1,1,'Downtown Store','North',101,'iPhone 15','Electronics','Smartphones','2024-01-15',2,999.00,5.00,'Regular','Credit Card'),\n(2,1,'Downtown Store','North',102,'MacBook Pro','Electronics','Laptops','2024-01-15',1,1999.00,0.00,'Premium','Credit Card'),\n(3,2,'Mall Store','South',103,'Nike Air Max','Clothing','Shoes','2024-01-16',3,120.00,10.00,'Regular','Cash'),\n(4,2,'Mall Store','South',104,'Levi Jeans','Clothing','Pants','2024-01-16',2,80.00,0.00,'Student','Debit Card'),\n(5,3,'Airport Store','East',105,'Harry Potter Book','Books','Fiction','2024-01-17',5,15.00,0.00,'Regular','Credit Card'),\n(6,3,'Airport Store','East',106,'Kindle Paperwhite','Electronics','E-readers','2024-01-17',1,129.00,15.00,'Premium','Credit Card');",
          "nerd_notes": "Discount percentages are applied in revenue calculations; use NULLIF to avoid division by zero in ratio calculations.",
          "compat_examples": {
            "postgres": "-- PostgreSQL: use SERIAL/IDENTITY and NUMERIC for currency where precision matters\n-- CREATE TABLE retail_sales (sale_id SERIAL PRIMARY KEY, store_id INT, store_name TEXT, region TEXT, product_id INT, product_name TEXT, category TEXT, subcategory TEXT, sale_date DATE, quantity INT, unit_price NUMERIC(10,2), discount_percent NUMERIC(5,2), customer_type TEXT, payment_method TEXT);",
            "mysql": "-- MySQL: use AUTO_INCREMENT and DECIMAL for currency\n-- CREATE TABLE retail_sales (sale_id INT AUTO_INCREMENT PRIMARY KEY, store_id INT, store_name VARCHAR(255), region VARCHAR(100), product_id INT, product_name VARCHAR(255), category VARCHAR(100), subcategory VARCHAR(100), sale_date DATE, quantity INT, unit_price DECIMAL(10,2), discount_percent DECIMAL(5,2), customer_type VARCHAR(50), payment_method VARCHAR(50));",
            "oracle": "-- Oracle: use NUMBER and consider sequences for legacy compatibility\n-- CREATE TABLE retail_sales (sale_id NUMBER PRIMARY KEY, store_id NUMBER, store_name VARCHAR2(4000), region VARCHAR2(4000), product_id NUMBER, product_name VARCHAR2(4000), category VARCHAR2(4000), subcategory VARCHAR2(4000), sale_date DATE, quantity NUMBER, unit_price NUMBER(10,2), discount_percent NUMBER(5,2), customer_type VARCHAR2(4000), payment_method VARCHAR2(4000));\n-- -- Use a SEQUENCE and insert with sequence_name.NEXTVAL for sale_id if not using IDENTITY."
          }
        },
        {
          "name": "retail_multi_level",
          "description": "Question: how do we compute multi-level sales metrics (region -> store -> category -> subcategory)?",
          "sql": "SELECT region, store_name, category, subcategory, COUNT(*) AS total_transactions, SUM(quantity) AS total_units_sold, ROUND(SUM(quantity * unit_price * (1 - discount_percent/100)),2) AS total_revenue, ROUND(AVG(quantity * unit_price * (1 - discount_percent/100)),2) AS avg_transaction_value, ROUND(AVG(unit_price),2) AS avg_unit_price FROM retail_sales GROUP BY region, store_name, category, subcategory ORDER BY region, store_name, category, subcategory;",
          "nerd_notes": "When producing large reports, consider materializing intermediate summaries.",
          "compat_examples": {
            "postgres": "-- Postgres: complex GROUP BY queries are supported; consider MATERIALIZED VIEW for heavy reports.",
            "mysql": "-- MySQL: GROUP BY queries are supported; consider using temporary tables or aggregated tables for performance.",
            "oracle": "-- Oracle: consider materialized views for heavy aggregation workloads."
          }
        }
      ]
    }
  ],
  "final_cleanup": {
    "title": "Final Cleanup",
    "description": "Drop demo tables created by this lesson.",
    "examples": [
      {
        "name": "final_cleanup",
        "sql": "DROP TABLE IF EXISTS sales; DROP TABLE IF EXISTS sales_rollup;",
        "description": "Drop demo tables.",
          "nerd_notes": "Idempotent cleanup that is safe to run multiple times. Keep cleanup lightweight so validator runs remain fast.",
          "compat_examples": {
            "postgres": "-- Portable SQL: DROP TABLE IF EXISTS is supported in Postgres. For cascades, add CASCADE if you need to drop dependent objects.",
            "mysql": "-- Portable SQL: DROP TABLE IF EXISTS works in MySQL. Add CASCADE for foreign keys if necessary.",
            "oracle": "-- Oracle: DROP TABLE table_name CASCADE CONSTRAINTS to drop dependent constraints; older Oracle doesn't support IF EXISTS."
          }
      }
    ]
  },
  "exercises": [
    {
      "id": "basic-select",
      "prompt": "Show the first 5 rows from `sales`.",
      "answer_sql": "SELECT * FROM sales LIMIT 5;"
    },
    {
      "id": "aggregate-1",
      "prompt": "Count rows grouped by `sale_id`.",
      "answer_sql": "SELECT sale_id, COUNT(*) AS cnt FROM sales GROUP BY sale_id ORDER BY cnt DESC;"
    },
    {
      "id": "filter-top",
      "prompt": "Select the top 10 rows where `sale_id` is positive (if numeric) or not null otherwise.",
      "answer_sql": "SELECT * FROM sales WHERE sale_id IS NOT NULL AND sale_id > 0 LIMIT 10;"
    }
  ]
}
