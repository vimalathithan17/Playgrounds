{
  "title": "Constraints Overview",
  "description": "A narrative guide to core table constraints in DuckDB (NOT NULL, DEFAULT, PRIMARY KEY, UNIQUE, CHECK, simulated FOREIGN KEY patterns, and safe migration techniques). Each section starts with a practical question and ends with an idempotent runnable snippet plus cross-engine notes.",
  "sections": [
    {
      "title": "0. Introduction: Core Constraints",
      "description": "Why constraints matter: push invariants to the data layer â€” NOT NULL, DEFAULT, PRIMARY KEY, UNIQUE, CHECK, and simulated FOREIGN KEY patterns.",
      "examples": [],
      "narrative": "Constraints capture non-negotiable data rules near the source. They reduce downstream COALESCEs and dedupe logic, surface errors earlier, and document schema intent. Even where enforcement is limited, patterns like CTAS filtering and orphan scans provide practical safeguards.",
      "nerd_notes": "Think: PK = identity (unique + not null), UNIQUE = alternate key, NOT NULL = presence, DEFAULT = convenience, CHECK = domain rule, FK = relationship integrity (simulate if not enforced)."
    },
    {
      "title": "1. Create products table with constraints",
      "description": "Establish a base table demonstrating multiple constraint types together.",
      "examples": [
        {
          "name": "create_products",
          "sql": "DROP TABLE IF EXISTS products;\nCREATE TABLE products (\n  product_id INTEGER PRIMARY KEY,\n  name TEXT NOT NULL,\n  sku TEXT UNIQUE,\n  price DOUBLE CHECK (price >= 0),\n  stock_quantity INTEGER DEFAULT 0\n);\nINSERT INTO products VALUES (1,'Widget','W-100',10.0,100),(2,'Gadget','G-200',25.0,50);\nSELECT * FROM products;",
          "description": "Question: how do we define a small product table that showcases PRIMARY KEY, NOT NULL, UNIQUE, CHECK, and DEFAULT in one place?",
          "nerd_notes": "Combining constraints early documents invariants. DuckDB treats constraints mostly as metadata (except NOT NULL). Use CHECK for simple domain rules; complex validation can happen in ETL staging.",
          "compat_examples": {
            "postgres": "-- Postgres: prefer NUMERIC(10,2) for currency; add GENERATED ALWAYS AS IDENTITY if auto IDs desired.",
            "mysql": "-- MySQL: use DECIMAL(10,2) for currency; INT AUTO_INCREMENT PRIMARY KEY if you need auto IDs.",
            "oracle": "-- Oracle: use NUMBER types; add GENERATED BY DEFAULT AS IDENTITY for surrogate keys if needed." 
          }
        }
      ],
      "narrative": "We start with a compact table so later examples can focus on isolating one constraint at a time.",
      "nerd_notes": "Idempotent demo pattern (DROP + CREATE) keeps lessons repeatable; production migrations should use ALTER or copy-swap patterns."
    },
    {
      "title": "1.5 Cheat Sheet: Common Patterns",
      "description": "Copy-ready snippets to apply constraints and validate data quickly.",
      "examples": [
        {
          "name": "cs_not_null_default_combo",
          "description": "NOT NULL with DEFAULT for clean inserts.",
          "sql": "DROP TABLE IF EXISTS cs_people;\nCREATE TABLE cs_people (id INTEGER PRIMARY KEY, name TEXT NOT NULL DEFAULT 'Unknown');\nINSERT INTO cs_people(id) VALUES (1);\nSELECT * FROM cs_people ORDER BY id;\nDROP TABLE IF EXISTS cs_people;",
          "nerd_notes": "Defaults prevent NULL floods while NOT NULL asserts presence."
        },
        {
          "name": "cs_unique_alt_key",
          "description": "Alternate key via UNIQUE.",
          "sql": "DROP TABLE IF EXISTS cs_users;\nCREATE TABLE cs_users (user_id INTEGER PRIMARY KEY, email TEXT UNIQUE);\nINSERT INTO cs_users VALUES (1,'a@example.com'),(2,'b@example.com');\nSELECT * FROM cs_users ORDER BY user_id;\nDROP TABLE IF EXISTS cs_users;",
          "nerd_notes": "Use UNIQUE for human identifiers; pair with NOT NULL when appropriate."
        },
        {
          "name": "cs_check_ctas_filter",
          "description": "CHECK-like enforcement via filtered CTAS.",
          "sql": "DROP TABLE IF EXISTS cs_in;\nDROP TABLE IF EXISTS cs_out;\nCREATE TABLE cs_in(id INTEGER, qty INTEGER);\nINSERT INTO cs_in VALUES (1,5),(2,-1);\nCREATE TABLE cs_out AS SELECT * FROM cs_in WHERE qty >= 0;\nSELECT * FROM cs_out ORDER BY id;\nDROP TABLE IF EXISTS cs_out; DROP TABLE IF EXISTS cs_in;",
          "nerd_notes": "Stage data, filter invalids, then adopt the clean table."
        },
        {
          "name": "cs_fk_orphan_scan",
          "description": "LEFT JOIN anti-check for orphans.",
          "sql": "DROP TABLE IF EXISTS cs_parent;\nDROP TABLE IF EXISTS cs_child;\nCREATE TABLE cs_parent(pid INTEGER PRIMARY KEY);\nCREATE TABLE cs_child(cid INTEGER, pid INTEGER);\nINSERT INTO cs_parent VALUES (1);\nINSERT INTO cs_child VALUES (10,1),(11,2);\nSELECT c.cid, c.pid, CASE WHEN p.pid IS NULL THEN 'ORPHAN' ELSE 'OK' END AS status\nFROM cs_child c LEFT JOIN cs_parent p ON c.pid = p.pid ORDER BY c.cid;\nDROP TABLE IF EXISTS cs_child; DROP TABLE IF EXISTS cs_parent;",
          "nerd_notes": "Run orphan scans on ingest to mimic FK assurance."
        }
      ],
      "narrative": "Use these building blocks to encode common invariants quickly.",
      "nerd_notes": "All snippets are idempotent; safe to re-run in CI or the playground."
    },
    {
      "title": "1.6 Pitfalls, Tips, and Q&A",
      "description": "Avoid common mistakes; clarify semantics.",
      "examples": [
        {
          "name": "pitfall_unique_and_nulls",
          "description": "Q: Why are multiple NULLs allowed with UNIQUE?",
          "sql": "",
          "nerd_notes": "UNIQUE treats NULL as 'unknown' so multiple NULLs are permitted in many engines. Add NOT NULL to disallow."
        },
        {
          "name": "tip_copy_swap_migrations",
          "description": "Tip: Use copy-validate-swap for big changes.",
          "sql": "",
          "nerd_notes": "Safer than in-place ALTER in analytic engines; validate counts and invariants before swapping."
        },
        {
          "name": "question_pk_vs_unique",
          "description": "Q: When to choose PRIMARY KEY vs UNIQUE?",
          "sql": "",
          "nerd_notes": "PRIMARY KEY conveys table identity and forbids NULL; UNIQUE is best for alternate identifiers and can allow NULL."
        },
        {
          "name": "tricky_check_aggregation",
          "description": "Q: Can CHECK reference aggregates?",
          "sql": "",
          "nerd_notes": "No; CHECK works per-row. Use ETL validations or materialized checks for cross-row constraints."
        },
        {
          "name": "fundamental_fk_validation_job",
          "description": "Q: How to approximate FOREIGN KEY enforcement in pipelines?",
          "sql": "",
          "nerd_notes": "Schedule orphan scans and fail the job when count > 0; quarantine bad rows for triage."
        }
      ],
      "narrative": "These notes help you pick the right constraint and avoid silent data-quality issues.",
      "nerd_notes": "Document constraint intent in DDL comments or adjacent docs to aid future maintainers."
    },
    {
      "title": "2. Violations and enforcement",
      "description": "Show what happens (conceptually) when constraint rules would be broken.",
      "examples": [
        {
          "name": "violation_examples",
          "sql": "-- Uncomment lines to observe failures in an interactive session\n-- INSERT INTO products (product_id, name) VALUES (3, NULL);          -- NOT NULL violation\n-- INSERT INTO products (product_id, name, sku) VALUES (3,'DupSKU','G-200'); -- UNIQUE violation\nSELECT product_id, name, sku, price, stock_quantity FROM products ORDER BY product_id;",
          "description": "Question: how would NOT NULL or UNIQUE violations appear if we attempted them?",
          "nerd_notes": "Keeping failing statements commented preserves validator success while documenting expected errors. Always capture the intent of failures in teaching material.",
          "compat_examples": {
            "postgres": "-- Same errors raised with detailed constraint names in messages.",
            "mysql": "-- MySQL emits error codes (e.g., 1062 for duplicate key).",
            "oracle": "-- Oracle raises ORA-00001 for unique constraint violations; ORA-01400 for NOT NULL." 
          }
        }
      ],
      "narrative": "Surfacing violations clarifies each constraint's protective role without breaking automated validation.",
      "nerd_notes": "In CI you typically run only successful scripts; keep a separate document for intentional failure repro steps."
    },
    {
      "title": "3. Adding constraints later (safe patterns)",
      "description": "Use a copy-swap pattern to retrofit or tighten constraints when ALTER ADD is limited.",
      "examples": [
        {
          "name": "add_constraint",
          "sql": "-- Add a NOT NULL (or stricter rule) by creating revised table then swapping\nDROP TABLE IF EXISTS products_new;\nCREATE TABLE products_new AS SELECT * FROM products;\n-- (Optionally validate / transform here)\nDROP TABLE IF EXISTS products;\nALTER TABLE products_new RENAME TO products;\nSELECT COUNT(*) AS row_count_after_swap FROM products;",
          "description": "Question: how can we safely add or tighten a constraint in DuckDB when direct ALTER ADD is limited?",
          "nerd_notes": "Pattern: create copy with desired schema, populate only valid rows, swap names. Validate row counts match before dropping source. This generalizes to type changes and CHECK additions.",
          "compat_examples": {
            "postgres": "-- Could instead: ALTER TABLE products ADD COLUMN new_col ...; ALTER TABLE ... ADD CONSTRAINT ...;",
            "mysql": "-- ALTER TABLE supports ADD CONSTRAINT; copy-swap still useful for large reorganizations.",
            "oracle": "-- Use ENABLE NOVALIDATE then VALIDATE CONSTRAINT for phased rollout." 
          }
        }
      ],
      "narrative": "Copy-swap gives transactional clarity in analytic contexts where full ALTER semantics are absent or limited.",
      "nerd_notes": "Always test on a temp table first for large data sets; measure row counts + checksums to ensure fidelity."
    },
    {
      "title": "4. CHECK constraints examples",
      "description": "Simulate adding a CHECK by filtering invalid rows into a new table.",
      "examples": [
        {
          "name": "check_examples",
          "sql": "ALTER TABLE products ADD COLUMN discount DOUBLE DEFAULT 0;\nCREATE TABLE products_tmp AS SELECT product_id, name, sku, price, stock_quantity, discount FROM products WHERE discount >= 0;\nDROP TABLE IF EXISTS products;\nALTER TABLE products_tmp RENAME TO products;\nSELECT MIN(discount) AS min_discount_ok FROM products;",
          "description": "Question: how do we enforce a new rule (discount >= 0) on existing rows without native ALTER ADD CHECK?",
          "nerd_notes": "Build a filtered CTAS capturing only valid rows; store rejects separately if auditing. Works for range rules and simple relational checks.",
          "compat_examples": {
            "postgres": "-- ALTER TABLE products ADD CONSTRAINT chk_discount CHECK (discount >= 0) NOT VALID; VALIDATE CONSTRAINT chk_discount;",
            "mysql": "-- Modern MySQL enforces CHECK; earlier versions ignored it (pre-8.0.16).",
            "oracle": "-- ALTER TABLE products ADD CONSTRAINT chk_discount CHECK (discount >= 0) ENABLE NOVALIDATE." 
          }
        }
      ],
      "narrative": "Filtered-copy approach is universal and explicit, making hidden data quality issues visible during migration.",
      "nerd_notes": "For complex expressions prefer staging tables plus validation queries before adopting new constraints."
    },
    {
      "title": "5. NOT NULL + DEFAULT patterns",
      "description": "Demonstrate providing defaults while requiring presence for business-critical columns.",
      "examples": [
        {
          "name": "notnull_default_demo",
          "sql": "DROP TABLE IF EXISTS customer_profiles;\nCREATE TABLE customer_profiles (\n  profile_id INTEGER PRIMARY KEY,\n  customer_id INTEGER NOT NULL,\n  first_name TEXT NOT NULL,\n  last_name TEXT NOT NULL,\n  country TEXT NOT NULL DEFAULT 'US',\n  created_ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\nINSERT INTO customer_profiles VALUES (1,101,'Alice','Smith','US',CURRENT_TIMESTAMP),(2,102,'Bob','Lee','CA',CURRENT_TIMESTAMP);\nSELECT * FROM customer_profiles ORDER BY profile_id;",
          "description": "Question: how do NOT NULL and DEFAULT combine to guarantee presence while reducing boilerplate in inserts?",
          "nerd_notes": "Pair DEFAULT with NOT NULL to centralize implicit values. Avoid sprinkling COALESCE in downstream queries.",
          "compat_examples": {
            "postgres": "-- IDENTICAL semantics; consider GENERATED ALWAYS AS IDENTITY for profile_id.",
            "mysql": "-- Use AUTO_INCREMENT for surrogate key; TIMESTAMP defaults vary by sql_mode.",
            "oracle": "-- Use DEFAULT CURRENT_TIMESTAMP; identity column for profile_id optionally." 
          }
        }
      ],
      "narrative": "Defaults cut repetition while NOT NULL asserts intent. This pairing forms the backbone of reliable dimension tables.",
      "nerd_notes": "Audit columns: if application always supplies a value, make it NOT NULL + possibly DEFAULT for convenience."
    },
    {
      "title": "6. PRIMARY KEY variants",
      "description": "Show column-level, table-level and composite PK definitions (simplified).",
      "examples": [
        {
          "name": "primary_key_variants",
          "sql": "DROP TABLE IF EXISTS pk_single_col;\nDROP TABLE IF EXISTS pk_named;\nDROP TABLE IF EXISTS pk_composite;\nCREATE TABLE pk_single_col (id INTEGER PRIMARY KEY, name TEXT);\nCREATE TABLE pk_named (id INTEGER, name TEXT, CONSTRAINT pk_named_id PRIMARY KEY(id));\nCREATE TABLE pk_composite (order_id INTEGER, product_id INTEGER, line_no INTEGER, PRIMARY KEY(order_id, product_id, line_no));\nINSERT INTO pk_single_col VALUES (1,'A'),(2,'B');\nINSERT INTO pk_named VALUES (1,'X'),(2,'Y');\nINSERT INTO pk_composite VALUES (10,100,1),(10,101,1);\nSELECT 'single' AS kind, * FROM pk_single_col UNION ALL SELECT 'named', * FROM pk_named;",
          "description": "Question: what are the forms of declaring a PRIMARY KEY (inline, named, composite)?",
          "nerd_notes": "Composite keys encode business identity; consider a surrogate key only if join fan-out or late arriving facts push complexity.",
          "compat_examples": {
            "postgres": "-- All forms identical; composite builds multicolumn btree index.",
            "mysql": "-- InnoDB clusters by PRIMARY KEY; choose carefully for write patterns.",
            "oracle": "-- Creates unique index; naming constraints helps future maintenance." 
          }
        }
      ],
      "narrative": "Different syntaxes convey the same invariant: row identity. Named constraints aid future ALTER/DROP maintenance.",
      "nerd_notes": "If future scaling needs a surrogate key, demote composite key to UNIQUE and add new PK."
    },
    {
      "title": "7. Simulated FOREIGN KEY patterns",
      "description": "Demonstrate maintaining parent/child relationships and detecting orphan rows without enforced FOREIGN KEY support.",
      "examples": [
        {
          "name": "foreign_key_simulation",
          "sql": "DROP TABLE IF EXISTS fk_items; DROP TABLE IF EXISTS fk_categories;\nCREATE TABLE fk_categories (category_id INTEGER PRIMARY KEY, name TEXT);\nINSERT INTO fk_categories VALUES (1,'Hardware'),(2,'Software');\nCREATE TABLE fk_items (\n  item_id INTEGER PRIMARY KEY,\n  category_id INTEGER,\n  name TEXT\n);\nINSERT INTO fk_items VALUES (10,1,'Hammer'),(11,2,'Editor'),(12,99,'Ghost Item');\n-- Detect orphan child rows (those lacking a matching parent)\nSELECT i.item_id, i.category_id, i.name, CASE WHEN c.category_id IS NULL THEN 'ORPHAN' ELSE 'OK' END AS fk_status\nFROM fk_items i LEFT JOIN fk_categories c USING(category_id)\nORDER BY i.item_id;",
          "description": "Question: how can we model and validate parentâ†’child relationships when the engine doesn't enforce FOREIGN KEY constraints?",
          "nerd_notes": "Pattern: (1) maintain parent table, (2) insert child rows, (3) run LEFT JOIN anti-checks to surface orphans. Schedule integrity queries in ETL/QA pipelines. Optionally quarantine orphans before analytics.",
          "compat_examples": {
            "postgres": "-- Native: CREATE TABLE fk_items (... category_id INTEGER REFERENCES fk_categories(category_id) ON DELETE CASCADE);",
            "mysql": "-- Native: FOREIGN KEY (category_id) REFERENCES fk_categories(category_id) ON DELETE SET NULL; (InnoDB only)",
            "oracle": "-- Native: FOREIGN KEY (category_id) REFERENCES fk_categories(category_id) ON DELETE NO ACTION;" 
          }
        }
      ],
      "narrative": "We simulate referential integrity with validation queries. Orphan detection queries become part of data quality checks.",
      "nerd_notes": "You can materialize a report of orphans and fail a pipeline if count > 0 to mimic enforced constraints."
    },
    {
      "title": "8. UNIQUE constraints (single & composite)",
      "description": "Demonstrate single-column and multi-column uniqueness plus nullable behavior.",
      "examples": [
        {
          "name": "unique_variants",
          "sql": "DROP TABLE IF EXISTS unique_demo;\nDROP TABLE IF EXISTS unique_composite;\nCREATE TABLE unique_demo (username TEXT UNIQUE, email TEXT UNIQUE, phone TEXT);\nCREATE TABLE unique_composite (user_id INTEGER, platform TEXT, handle TEXT, UNIQUE(user_id, platform));\nINSERT INTO unique_demo VALUES ('alice','alice@example.com','555-1'),('bob','bob@example.com',NULL);\nINSERT INTO unique_composite VALUES (1,'web','alice_web'),(1,'mobile','alice_mob');\nSELECT 'single' AS kind, * FROM unique_demo;",
          "description": "Question: how do single-column UNIQUE constraints differ from composite UNIQUE constraints?",
          "nerd_notes": "Single-column UNIQUE prevents duplicates per column; composite enforces tuple uniqueness. Multiple NULLs are typically allowed (engine-dependent).",
          "compat_examples": {
            "postgres": "-- Allows multiple NULLs; create partial unique indexes for filtered uniqueness.",
            "mysql": "-- Multiple NULLs allowed (InnoDB) but treat carefully with queries; consider IS NOT NULL filters.",
            "oracle": "-- Multiple NULLs allowed; use function-based indexes to normalize values first." 
          }
        }
      ],
      "narrative": "Choosing between single and composite uniqueness shapes how natural keys are represented and validated.",
      "nerd_notes": "Avoid over-constraining with many UNIQUE indexesâ€”each adds write overhead."
    },
    {
  "title": "9. CHECK constraint complexity",
      "description": "Illustrate combining several domain checks succinctly (simplified version).",
      "examples": [
        {
          "name": "check_complex_demo",
          "sql": "DROP TABLE IF EXISTS order_line;\nCREATE TABLE order_line (\n  order_id INTEGER,\n  item_id INTEGER,\n  qty INTEGER CHECK (qty > 0),\n  unit_price DOUBLE CHECK (unit_price >= 0),\n  discount DOUBLE DEFAULT 0 CHECK (discount BETWEEN 0 AND 100),\n  line_total DOUBLE\n);\nINSERT INTO order_line VALUES (1,1,2,10.0,0,20.0),(1,2,1,15.0,10,13.5);\nSELECT * FROM order_line;",
          "description": "Question: how can multiple simple CHECK constraints create guardrails for numeric inputs?",
          "nerd_notes": "Small atomic CHECK constraints are clearer than one mega-condition. They localize error sources and simplify future edits.",
          "compat_examples": {
            "postgres": "-- Combine or separate constraints; naming each aids targeted troubleshooting.",
            "mysql": "-- Modern MySQL enforces; legacy versions silently ignored CHECK clauses.",
            "oracle": "-- Consider DISABLE NOVALIDATE for phased adoption on large legacy tables." 
          }
        }
      ],
      "narrative": "Atomic checks compose a safety net that is both readable and maintainable compared to sprawling boolean expressions.",
      "nerd_notes": "Prefer multiple named checks over one aggregated predicate for clarity."
    },
    {
    "title": "10. Constraint management & cleanup",
      "description": "Centralized cleanup to keep re-runs idempotent.",
      "examples": [
        {
          "name": "cleanup",
  "sql": "DROP TABLE IF EXISTS products; DROP TABLE IF EXISTS products_tmp; DROP TABLE IF EXISTS customer_profiles; DROP TABLE IF EXISTS pk_single_col; DROP TABLE IF EXISTS pk_named; DROP TABLE IF EXISTS pk_composite; DROP TABLE IF EXISTS fk_items; DROP TABLE IF EXISTS fk_categories; DROP TABLE IF EXISTS unique_demo; DROP TABLE IF EXISTS unique_composite; DROP TABLE IF EXISTS order_line;",
          "description": "Question: how do we drop all objects created during constraint demonstrations?",
          "nerd_notes": "Cleanup ensures subsequent lessons start clean; production systems would ALTER not DROP.",
          "compat_examples": {
            "postgres": "-- Add CASCADE if dependent views exist.",
            "mysql": "-- DROP TABLE IF EXISTS supported; ensure transactions committed first.",
            "oracle": "-- Use PURGE if recycle bin side-effects undesired." 
          }
        }
      ],
      "narrative": "Keeping educational schemas tidy avoids cross-test contamination.",
      "nerd_notes": "Consider a dedicated schema per lesson in multi-user environments."
    }
  ],
  "exercises": [
    { "id": "basic-select", "prompt": "Show the first 5 rows from `products`.", "answer_sql": "SELECT * FROM products LIMIT 5;" },
    { "id": "aggregate-1", "prompt": "Count rows grouped by `product_id`.", "answer_sql": "SELECT product_id, COUNT(*) AS cnt FROM products GROUP BY product_id ORDER BY cnt DESC;" },
    { "id": "filter-top", "prompt": "Select the top 10 rows where `product_id` is positive (if numeric) or not null otherwise.", "answer_sql": "SELECT * FROM products WHERE product_id IS NOT NULL AND product_id > 0 LIMIT 10;" }
  ]
}
